# How to Add Mock Data to RAG System

## ğŸ“ Where to Put Information

### Database Location
Mock knowledge data goes directly into the PostgreSQL database in two tables:
- `knowledge_documents` - Document metadata
- `knowledge_chunks` - Actual content chunks with embeddings

### Connection Details
- **Host**: localhost
- **Port**: 5433 (mapped from container's 5432)
- **Database**: purpose_agnostic_agent
- **User**: postgres
- **Password**: password

## ğŸš€ Quick Start - Insert Mock Data

### Method 1: Using Docker (Recommended)

```powershell
# Run the SQL script through Docker
docker exec -i purpose-agnostic-agent-postgres psql -U postgres -d purpose_agnostic_agent < scripts/insert-mock-knowledge.sql
```

### Method 2: Using psql Directly

```powershell
# If you have psql installed locally
psql -h localhost -p 5433 -U postgres -d purpose_agnostic_agent -f scripts/insert-mock-knowledge.sql
```

### Method 3: Using Docker Compose Exec

```powershell
# Copy script into container and execute
docker cp scripts/insert-mock-knowledge.sql purpose-agnostic-agent-postgres:/tmp/
docker exec purpose-agnostic-agent-postgres psql -U postgres -d purpose_agnostic_agent -f /tmp/insert-mock-knowledge.sql
```

## ğŸ“š Mock Data Included

I've created **6 mock documents** with **13 knowledge chunks** covering:

### 1. Docker Basics (3 chunks)
- What is Docker and containers
- Common Docker commands
- Benefits of using Docker

### 2. Password Reset Guide (2 chunks)
- Step-by-step reset instructions
- Troubleshooting tips

### 3. REST API Guide (2 chunks)
- REST principles and architecture
- HTTP methods and status codes

### 4. Kubernetes Basics (2 chunks)
- What is Kubernetes
- Key features and kubectl commands

### 5. Creative Writing Tips (2 chunks)
- Character development and plot structure
- Show don't tell, dialogue tips

### 6. Troubleshooting Guide (2 chunks)
- Internet connection problems
- Computer performance issues

## ğŸ§ª Testing After Insertion

### Test 1: Docker Question
```powershell
$headers = @{ "x-api-key" = "pak_dev_key_12345"; "Content-Type" = "application/json" }
$body = '{"agent_id":"technical-expert","question":"What is Docker?"}'
Invoke-RestMethod -Uri "http://localhost:3000/api/chat" -Method Post -Headers $headers -Body $body -ContentType "application/json"
```

Expected: Answer about Docker with citations!

### Test 2: Password Reset
```powershell
$body = '{"agent_id":"tech-support","question":"How do I reset my password?"}'
Invoke-RestMethod -Uri "http://localhost:3000/api/chat" -Method Post -Headers $headers -Body $body -ContentType "application/json"
```

Expected: Step-by-step password reset instructions!

### Test 3: Writing Tips
```powershell
$body = '{"agent_id":"creative-writer","question":"What is show dont tell in writing?"}'
Invoke-RestMethod -Uri "http://localhost:3000/api/chat" -Method Post -Headers $headers -Body $body -ContentType "application/json"
```

Expected: Explanation of show don't tell with examples!

## ğŸ“Š Verify Data Insertion

### Check Documents
```sql
SELECT source_path, category, total_chunks 
FROM knowledge_documents 
WHERE source_path LIKE 'mock/%';
```

### Check Chunks
```sql
SELECT 
  d.source_path,
  c.chunk_index,
  LEFT(c.content, 100) as content_preview,
  c.token_count
FROM knowledge_chunks c
JOIN knowledge_documents d ON c.document_id = d.id
WHERE d.source_path LIKE 'mock/%'
ORDER BY d.source_path, c.chunk_index;
```

### Count Total
```sql
SELECT 
  COUNT(DISTINCT d.id) as documents,
  COUNT(c.id) as chunks
FROM knowledge_documents d
LEFT JOIN knowledge_chunks c ON d.id = c.document_id
WHERE d.source_path LIKE 'mock/%';
```

## âš ï¸ Important Notes

### About Embeddings
The mock data uses **simplified embeddings** (arrays filled with constant values like 0.1, 0.2, etc.). These are for testing purposes only.

**Why this works for testing:**
- The vector similarity search will still function
- You'll get results based on the mock embeddings
- Perfect for testing the RAG pipeline

**For production:**
- Use real embeddings generated by Ollama or OpenAI
- Real embeddings capture semantic meaning
- Better search relevance and accuracy

### Embedding Dimensions
- Mock data uses **768 dimensions** (Ollama nomic-embed-text format)
- If you switch to OpenAI embeddings, you'll need 1536 dimensions
- Current system is configured for 768 dimensions

## ğŸ”§ Adding Your Own Mock Data

### Template for New Document

```sql
-- 1. Insert document metadata
INSERT INTO knowledge_documents (id, source_path, category, file_hash, total_chunks, metadata)
VALUES 
  ('YOUR-UUID-HERE', 'mock/your-topic.txt', 'general', 'mock_hash_X', 2, '{"type": "mock", "topic": "your-topic"}')
ON CONFLICT (source_path) DO NOTHING;

-- 2. Insert knowledge chunks
INSERT INTO knowledge_chunks (document_id, chunk_index, content, embedding, token_count)
VALUES (
  'YOUR-UUID-HERE',  -- Same UUID as document
  0,  -- Chunk index (0, 1, 2, ...)
  'Your knowledge content here. This should be a paragraph or section of information.',
  array_fill(0.7, ARRAY[768])::vector,  -- Mock embedding (change 0.7 to different values for different docs)
  50  -- Approximate token count
) ON CONFLICT (document_id, chunk_index) DO NOTHING;
```

### Tips for Creating Mock Data:
1. **Use unique UUIDs** for each document
2. **Vary embedding values** (0.1, 0.2, 0.3, etc.) for different documents
3. **Keep chunks focused** - one topic per chunk
4. **Estimate token count** - roughly 1 token per 4 characters
5. **Use meaningful content** - actual information the agent can use

## ğŸ¯ Categories

The system supports different categories for knowledge organization:
- `general` - General knowledge (default)
- `technical` - Technical documentation
- `support` - Support and troubleshooting
- `creative` - Creative content
- Custom categories as needed

## ğŸ”„ Updating Mock Data

### To Replace Existing Mock Data:
```sql
-- Delete old mock data
DELETE FROM knowledge_chunks WHERE document_id IN (
  SELECT id FROM knowledge_documents WHERE source_path LIKE 'mock/%'
);
DELETE FROM knowledge_documents WHERE source_path LIKE 'mock/%';

-- Then run insert script again
```

### To Add More Data:
Just run additional INSERT statements with new UUIDs and content.

## ğŸ› Troubleshooting

### Issue: "No results found"
**Solution:** Check if data was inserted:
```sql
SELECT COUNT(*) FROM knowledge_chunks;
```

### Issue: "Connection refused"
**Solution:** Ensure PostgreSQL container is running:
```powershell
docker-compose ps postgres
```

### Issue: "Permission denied"
**Solution:** Use postgres user with password "password"

### Issue: Agent still says "no information"
**Possible causes:**
1. Data not inserted - verify with SELECT queries
2. Embeddings don't match query - this is expected with mock embeddings
3. Similarity threshold too high - mock embeddings may not meet threshold

## ğŸ“ˆ Next Steps

### For Better Results:
1. **Generate Real Embeddings**: Use Ollama to create actual embeddings
2. **Add More Content**: More chunks = better coverage
3. **Organize by Category**: Use categories to filter results
4. **Test Different Queries**: See what works and what doesn't

### For Production:
1. Implement proper document ingestion pipeline
2. Use real embeddings from Ollama/OpenAI
3. Add document versioning
4. Implement incremental updates
5. Add metadata for better filtering

## âœ… Success Checklist

- [ ] PostgreSQL container is running
- [ ] Mock data SQL script executed successfully
- [ ] Verified data with SELECT queries
- [ ] Tested chat API with relevant questions
- [ ] Received answers with citations
- [ ] Ready to add more knowledge!

## ğŸ‰ You're Ready!

Once you've inserted the mock data, your RAG system is fully functional and ready to answer questions based on the knowledge base!
